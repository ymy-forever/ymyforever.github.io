{"meta":{"title":"ymy is watching u!!!!","subtitle":"","description":"Live my life with passion!","author":"ymy","url":"https://ymyforever.netlify.app","root":"/"},"pages":[{"title":"about","date":"2020-08-30T07:08:08.000Z","updated":"2022-08-14T02:05:40.811Z","comments":true,"path":"about/index.html","permalink":"https://ymyforever.netlify.app/about/index.html","excerpt":"","text":"DLUT计科到西交软院，计算机宇宙的小小探索者，请多指教~"},{"title":"aDream","date":"2020-09-15T02:32:56.000Z","updated":"2020-09-17T03:05:00.616Z","comments":true,"path":"secret/aDream.html","permalink":"https://ymyforever.netlify.app/secret/aDream.html","excerpt":"为什么会做这样的一场梦呢？ 为什么做了还让我醒来呢？ 这大概是我最不愿意醒来的梦吧。","text":"为什么会做这样的一场梦呢？ 为什么做了还让我醒来呢？ 这大概是我最不愿意醒来的梦吧。 求不得，求不得，求不得。 小的时候也做过这种怅然若失的梦，那个时候想要漂亮的文具，现在呢，想要完美的感情。 不过是想要得到偶像的认可罢了。 认可是自己给的，不要再傻了。 加油吧！ 最后，真好，我还有这一方自由乐园。"},{"title":"tags","date":"2022-08-14T01:55:25.992Z","updated":"2022-08-14T01:55:25.992Z","comments":false,"path":"tags/index.html","permalink":"https://ymyforever.netlify.app/tags/index.html","excerpt":"","text":""},{"title":"littletalk","date":"2020-09-14T03:58:28.000Z","updated":"2020-09-17T03:04:46.763Z","comments":true,"path":"secret/littletalk.html","permalink":"https://ymyforever.netlify.app/secret/littletalk.html","excerpt":"也许这就是偶像吧。每一次新的发现都能给我很大的精神震撼。 我一直以为庸人才应当在规则中生活，我这种疯子才应当指定规则。 人生短暂，我们来不及循规蹈矩。 我的生活永远与众不同。 这是多么狂妄自大的话啊，从我认识的其他任何一个人嘴里说出来都显得如此违和，只有你，你配得上这句话。","text":"也许这就是偶像吧。每一次新的发现都能给我很大的精神震撼。 我一直以为庸人才应当在规则中生活，我这种疯子才应当指定规则。 人生短暂，我们来不及循规蹈矩。 我的生活永远与众不同。 这是多么狂妄自大的话啊，从我认识的其他任何一个人嘴里说出来都显得如此违和，只有你，你配得上这句话。 我是一个在规则内循规蹈矩惯了的人，甚至利用规则谋求自己的利益。也是为了父母的规则，因为恐惧，恐惧父母得知女儿竟然和女生搅在一起时，那对我是灭顶之灾。 所以我选择了放弃，长痛不如短痛的放弃。我还爱吗？我告诉自己不爱了。 大学两年来，碌碌无为，既没有增长专业知识，也没有做出什么了不起的事情。我只是校园里千万颗齿轮里的一个，大齿轮，小齿轮，都是齿轮而已。 仰山之高，往往自惭形秽。可是功夫没到家，你没有资格。 对自己狠一点，再狠一点，你想要的，没人会给你，除了自己。 成为盖世英雄，而不要傻傻在原地等着。 你要的认可与肯定，只有自己能给你。 循此苦旅，循此苦旅。"}],"posts":[{"title":"经典模型：Swin Transformer","slug":"经典模型：Swin-Transformer","date":"2022-09-26T11:08:46.000Z","updated":"2022-09-27T03:26:41.271Z","comments":true,"path":"2022/09/26/经典模型：Swin-Transformer/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/26/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%EF%BC%9ASwin-Transformer/","excerpt":"","text":"模型结构 Swin（即Shifted Windows） Transformer可以作为CV的一种通用主干，用在分类、检测、语义分割等多种视觉任务上。 Swin Transformer的提出解决了ViT具有的以下两个问题： ViT中，由于每个token的size大小相同，难以捕捉多尺度信息。 ViT的自注意力计算复杂度是图像大小的二次方。 Swin-T构造了层次化特征图，并将自注意力的计算复杂度降为线性相关。 整体结构 Swin-T的整体架构如下图所示： Patch Partition 对于每个为H×W×3H \\times W \\times 3H×W×3的输入，划分为4×4×34 \\times 4 \\times 34×4×3大小的patch，每张图像被拆分为个patches，将每个patch展平作为一个token。 Linear Embedding 即一个全连接层，将每个大小为48的token映射到设定的维度C，此时，每张图片的输入变为了H4×W4×C\\frac{H}{4} \\times \\frac{W}{4} \\times C4H​×4W​×C，然后输入Swin Transformer Block。 Swin Transformer Block 对于Transformers中使用的全局自注意力机制，需要计算每个token与其它所有tokens间的关系，计算复杂度为token数的平方。不适用于对大量tokens进行密集预测或表示高分辨率图像等视觉问题。 W-MSA Swin-T通过在局部窗口中计算自注意力，将计算复杂度降低为token数的线性关系，设每个非重叠局部窗口中包含M×MM \\times MM×M个tokens。 MSA：有hwhwhw个tokens，每个token在全局计算hwhwhw次； W-MSA：有hwhwhw个tokens，每个token在全局计算M2M^2M2次。 SW-MSA W-MSA限制了跨窗口token间的交流与联系，从而限制了建模表征能力。作者提出了一种移位窗口划分方法SW-MSA，在模型中交替使用两种MSA方法（因此每个stage中Swin Transformer Block的数量都为偶数）。 所谓的移动窗口即将窗口循环位移，如下图所示： 但直接移位得到的窗口大小是不规则的，不利于并行计算，同时9个窗口也提升了计算成本。为了解决这个问题，将重新划分后的窗口进行拼接，如下图所示，得到4个窗口。 4个窗口中来自不同初始位置的patch不应进行自注意计算，因此使用mask机制，将不需要的注意力图置0。 相对位置偏置 在计算自注意力时，在计算相似度的过程中对每个head加入相对位置偏置，如下所示： 对于预训练中学到的相对位置偏置，可以通过双三次插值初始化具有不同窗口大小的微调模型。 Patch Merging Patch Merging层的功能是产生一个层次化表示，通过合并相邻的tokens，减少tokens的数目。 对于Stage1和Stage2间的Patch Merging层，将原维度为C的token合并为大小为4C的token，再使用一个线性层将输出维度降低为2C，token的数目降低为H8×W8\\frac{H}{8} \\times \\frac{W}{8}8H​×8W​。 在之后的每个stage中，都会改变张量的维度，从而形成一种层次化的特征。 代码实现","categories":[],"tags":[{"name":"经典模型","slug":"经典模型","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/"},{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"}]},{"title":"经典模型：Vision Transformer","slug":"经典模型：Vision-Transformer","date":"2022-09-26T00:32:10.000Z","updated":"2022-09-27T03:26:39.371Z","comments":true,"path":"2022/09/26/经典模型：Vision-Transformer/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/26/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%EF%BC%9AVision-Transformer/","excerpt":"","text":"模型介绍 可参考博客：https://blog.csdn.net/qq_39478403/article/details/118704747 模型结构 ViT主要使用Transformer的encoder部分 将一张图像分成若干个大小固定且相同的patch，将每个patch投影到线性空间中再加上位置编码 除了每个patch作为一个token外，在序列中添加一个额外的classification token 位置编码：（看下代码咋实现的） 使用可学习的一维位置编码（作者发现使用更高维的位置编码并没有带来显著的精度提升） 混合结构： 可以将原始图像使用CNN进行特征提取，将特征图按patch划分送入Transformer中。 实验设置 ViT使用： ViT与Bert类似，先在大数据集上训练，再在downstream任务上微调。在微调时，将预训练用的预测头换成一个用0初始化的DxK的前馈层，其中K代表下游任务总的类别数。 在微调时，使用更高分辨率的图像可以获得更好的结果。（patch大小不变，输入序列变成，不影响网络结构），这样会导致之前训练得到的位置编码无意义，因此在原来的位置编码上进行一个2D的插值。 实验结果： 当考虑预训练的训练代价时，ViT以更低的代价达到了SOTA水平 在自监督问题上，ViT很有应用前景 代码复现 Official Code：https://github.com/google-research/vision_transformer Using Code：https://github.com/jeonsworld/ViT-pytorch","categories":[],"tags":[{"name":"经典模型","slug":"经典模型","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/"},{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"}]},{"title":"论文阅读：Revisiting Pixel-Wise Supervision for Face Anti-Spoofing","slug":"论文阅读：Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing","date":"2022-09-22T02:17:48.000Z","updated":"2022-09-22T03:25:46.440Z","comments":true,"path":"2022/09/22/论文阅读：Revisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARevisiting-Pixel-Wise-Supervision-for-Face-Anti-Spoofing/","excerpt":"","text":"发表时间：2021 研究内容：像素级的人脸识别反欺诈方法 创新点：提出基于金字塔的监督方法，模型从多空间尺度上学习局部和全局的语义信息 Presentation Attack Detection研究历史： 传统算法关注于活体和手工特征的检测，需要丰富的任务级的先验知识。 活体检测：关注眨眼、面部和头部动作、视线追踪以及远程生理信号（这种方法需要长期的互动，容易被video attacks伪造）。 经典的handcrafted descriptors：从多种色彩空间中提取有效的欺诈模式，这种PA方法可以通过训练分类器捕捉，但在遇到未见过的场景或未知的PAs时就失效了。","categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"人脸识别","slug":"人脸识别","permalink":"https://ymyforever.netlify.app/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"}]},{"title":"论文阅读：Rethinking the ST-GCNs for 3D skeleton-based human action recognition","slug":"论文阅读：Rethinking-the-ST-GCNs-for-3D-skeleton-based-human-action-recognition","date":"2022-09-20T02:54:50.000Z","updated":"2022-09-22T02:18:47.677Z","comments":true,"path":"2022/09/20/论文阅读：Rethinking-the-ST-GCNs-for-3D-skeleton-based-human-action-recognition/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARethinking-the-ST-GCNs-for-3D-skeleton-based-human-action-recognition/","excerpt":"","text":"发表时间：2021 ST-GCN：Spatial-Temporal Graph Convolutional Network，用于解决骨骼数据的动作识别问题。 研究内容： 证明了在ST-GCN中很多操作对于人体动作识别是没必要的 提出了一个简单有效的策略捕捉全局图的相关性，对输入序列进行有效建模，同时将输入图序列降入欧几里得空间，可以使用多尺度时域滤波器捕捉动态信息。 研究现状： 骨骼数据成为人体动作识别的主流输入（与传统的RGB视频数据相比，信息更完整） 直接将结构化的数据重新排列，使得tensor适应基础的神经网络（由于骨骼数据中没有天然的局部性概念，深度学习的能力受到限制） 设计一种适应结构化数据的自定义神经网络（ST-GCN） TBC：GCN好难，看不懂","categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"人体动作识别","slug":"人体动作识别","permalink":"https://ymyforever.netlify.app/tags/%E4%BA%BA%E4%BD%93%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB/"},{"name":"GCN","slug":"GCN","permalink":"https://ymyforever.netlify.app/tags/GCN/"}]},{"title":"论文阅读：Social Distancing Alert with Smartwatches","slug":"论文阅读：Social-Distancing-Alert-with-Smartwatches","date":"2022-09-20T01:34:02.000Z","updated":"2022-09-20T02:49:35.605Z","comments":true,"path":"2022/09/20/论文阅读：Social-Distancing-Alert-with-Smartwatches/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ASocial-Distancing-Alert-with-Smartwatches/","excerpt":"","text":"发表时间：2022 研究内容：基于智能手表的社交距离警报系统SoDA，SoDA使用加速器和陀螺仪的数据和简单有效的视觉Transformer模型，识别违反社交距离的活动。 code：https://github.com/aiotgroup/SoDA 创新点： 应用价值 创建了一个数据集 证明了ViT是一种有效的方法？ 模型结构：","categories":[],"tags":[{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"}]},{"title":"论文阅读：PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer","slug":"论文阅读：PhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer","date":"2022-09-15T02:12:07.000Z","updated":"2022-09-19T03:40:36.913Z","comments":true,"path":"2022/09/15/论文阅读：PhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/","excerpt":"","text":"发表时间：2021 研究对象：rPPG，使用多波长 RGB 相机检测人体皮肤表面脉冲引起的细微颜色变化，实现测量心脏活动和其它生理信号。 研究意义：传统的检测方法会造成discomfort，并且长期检测不方便 Code：https://github.com/ZitongYu/PhysFormer rPPG研究历史： 早期使用经典的信号处理方法检测面部细微的颜色变化； 使用非端到端方法，首先生成预处理的信号特征，然后模型从这些特征图中捕捉rPPG特征（对预处理要求严格，忽略了全局特征）； 端到端的基于深度学习的方法（容易被复杂的背景信息影响）。 研究现状： ​ 现有的基于卷积神经网络的模型在时间和空间上的感受野受限，忽略了长期的时间和空间上的互动与感知。 PhysFormer网络架构： Stem：提取粗糙的局部时空特征 Tube Tokens：将stem输出划分为若干个时空tube token，将时空邻近语义聚合在一起，并减少后续transformer的计算量 Temporal Difference Multi-head Self-attention：与传统的自注意力机制不同，使用TDC计算距离，可以捕捉局部细粒度的时间差异特征 Spatio-temporal Feed-forward： 创新点：PhysFormer，一种端到端的视频transformer，联合使用了局部的和全局的时空特征。 使用时差引导全局注意力机制，强化rPPG的周期性特征，针对干扰完善局部时空特征； 使用受label distribution learning和curriculum learning启发的频域动态约束，为PhysFormer提供详细的监督，缓解过拟合。 PhysFormer不需要像其它transformer网络那样在大规模数据集上预训练，仅在rPPG数据集训练即可。 Label Distribution Learning：对于面部的rPPG信号，心率相近的视频会有相似的周期性特征。为了使得模型学习到这种特征，将心率估计问题看作一个多分类问题，有多少个心率就有多少类别，类别概率向量由高斯分布组成。 Curriculum Learning Guided Dynamic Loss：课程式学习是指模型从容易样本开始学习，逐步学习困难样本。在该任务中，从时域和频域两个方面限制模型学习，时域的限制更直接更容易学习，频域的限制较难学习，因此，使用动态的loss函数，逐步提高频域loss的比例。 实验：不同模型的对比实验、消融实验 Others：注意力图可视化","categories":[],"tags":[{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"PPG","slug":"PPG","permalink":"https://ymyforever.netlify.app/tags/PPG/"}]},{"title":"论文阅读：Model Behavior Preserving for Class-Incremental Learning","slug":"论文阅读：Model-Behavior-Preserving-for-Class-Incremental-Learning","date":"2022-08-23T02:45:11.000Z","updated":"2022-08-26T01:43:14.413Z","comments":true,"path":"2022/08/23/论文阅读：Model-Behavior-Preserving-for-Class-Incremental-Learning/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AModel-Behavior-Preserving-for-Class-Incremental-Learning/","excerpt":"","text":"发表时间：2022 研究内容：类增量学习，探讨在增量学习中应保留旧模型的哪些功能性属性。 研究现状：现有的增量学习方法忽略了CNN模型响应间的内部结构，KD的硬约束导致新模型出现混沌行为。 创新点： Feature Space：设计了一个INP Loss保持成对实例在旧模型上的相似性顺序（反映实例集间的相邻关系）； INP用于惩罚新模型在学习过程中每个实例相邻关系的变化。 a. 旧实例A在特征空间中与其它实例的相邻关系； b. 采用传统的KD，引入新实例G后，绝对位置的微小变化被严格限制； c. 采用INP Loss当相对位置没变时，就不会限制更新。 Label Space：设计了一个LPP Loss在输出空间的实例标签概率向量中保留标签排名列表（反映实例属于每一类的排名）； 介绍了一种可导的排名计算方法用于计算上述Loss。","categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读：Structural Knowledge Organization and Transfer for Class-Incremental Learning","slug":"论文阅读：Structural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning","date":"2022-08-21T08:05:32.000Z","updated":"2022-08-23T02:20:35.961Z","comments":true,"path":"2022/08/21/论文阅读：Structural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AStructural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning/","excerpt":"","text":"发表时间：2021 研究问题：类增量学习 研究现状： 经典的知识蒸馏方法忽略了信息点之间的关联，当新数据远多于旧数据时，面临着严重的偏差问题； KD：在特征空间中，孤立地限制单个训练样本的位置，样本间的关系可能会被改变，并导致分类错误。 SGKD：保持样本的结构化知识，包括样本的位置和样本间关系，确保蒸馏后样本仍能被正确地分类。 创新点： 使用一个memory knowledge graph(MKG)表征历史任务的结构化知识 在特征空间中的绝对位置（MKG中用顶点表示已知example间的特征向量） example间对应关系（边表示，使用余弦距离） 使用图插值机制丰富知识域、缓解类间样本不平衡问题 通过向MKG中插入假的顶点，扩充和平滑分散的数据集，假顶点通过mix两个真顶点的vector得到。 使用**结构化图知识蒸馏（SGKD）**迁移旧知识 顶点蒸馏损失 边蒸馏损失 人脸识别是怎么实现增加新样本的？ 人脸识别网络的本质是一个特征提取器，并不是分类器，识别人脸的时候，通过计算输出特征和人脸库中人脸的距离判断人脸所属对象。未涉及类增量学习。","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读：IDPT, Interconnected Dual Pyramid Transformer for Face Super-Resolution","slug":"论文阅读：IDPT","date":"2022-08-14T01:31:37.000Z","updated":"2022-09-19T03:43:55.484Z","comments":true,"path":"2022/08/14/论文阅读：IDPT/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AIDPT/","excerpt":"","text":"研究问题：人脸超分辨率技术 FSR：关注于恢复重要的面部结构 创新点：提出了一个新的、有效的基于Transformer的人脸超分辨率架构 设计了金字塔结构的encode/decoder的Transformer架构：分别提取粗糙纹理和精细纹理。 通过一个底部的金字塔特征提取器，将双重金字塔Transformer建立起联系。 在每个spatial layer插入一个新的融合调制模块：使用粗糙纹理完善对应的精细纹理，融合浅层的粗糙纹理和对应的深层的精细纹理。 FSR研究现状 现有技术在解决超低分辨率问题上表现很差 卷积难以描述不同域间的关联和捕捉远域间的依赖 网络结构：","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"FSR","slug":"FSR","permalink":"https://ymyforever.netlify.app/tags/FSR/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"}]},{"title":"HelloWorld!","slug":"HelloWorld","date":"2020-08-29T08:06:44.000Z","updated":"2022-08-13T09:48:18.595Z","comments":true,"path":"2020/08/29/HelloWorld/","link":"","permalink":"https://ymyforever.netlify.app/2020/08/29/HelloWorld/","excerpt":"","text":"A new world! 哈喽！历经一个下午博客终于搭建好了，原来是那么容易的一件事情，大一的时候想的很复杂，迟迟没能动手，现在也终于有了自己的小博客啦~ 未来灌水的文章还是会首先发在CSDN上，这里会分享一些重大的经历~已经大三了！要更努力学习！不要被些奇奇怪怪的事情干扰，奥里给！","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"经典模型","slug":"经典模型","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/"},{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"人脸识别","slug":"人脸识别","permalink":"https://ymyforever.netlify.app/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"},{"name":"人体动作识别","slug":"人体动作识别","permalink":"https://ymyforever.netlify.app/tags/%E4%BA%BA%E4%BD%93%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB/"},{"name":"GCN","slug":"GCN","permalink":"https://ymyforever.netlify.app/tags/GCN/"},{"name":"PPG","slug":"PPG","permalink":"https://ymyforever.netlify.app/tags/PPG/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"FSR","slug":"FSR","permalink":"https://ymyforever.netlify.app/tags/FSR/"}]}