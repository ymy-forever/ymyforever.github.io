{"meta":{"title":"ymy is watching u!!!!","subtitle":"","description":"Live my life with passion!","author":"ymy","url":"https://ymyforever.netlify.app","root":"/"},"pages":[{"title":"about","date":"2020-08-30T07:08:08.000Z","updated":"2022-08-14T02:05:40.811Z","comments":true,"path":"about/index.html","permalink":"https://ymyforever.netlify.app/about/index.html","excerpt":"","text":"DLUT计科到西交软院，计算机宇宙的小小探索者，请多指教~"},{"title":"aDream","date":"2020-09-15T02:32:56.000Z","updated":"2020-09-17T03:05:00.616Z","comments":true,"path":"secret/aDream.html","permalink":"https://ymyforever.netlify.app/secret/aDream.html","excerpt":"为什么会做这样的一场梦呢？ 为什么做了还让我醒来呢？ 这大概是我最不愿意醒来的梦吧。","text":"为什么会做这样的一场梦呢？ 为什么做了还让我醒来呢？ 这大概是我最不愿意醒来的梦吧。 求不得，求不得，求不得。 小的时候也做过这种怅然若失的梦，那个时候想要漂亮的文具，现在呢，想要完美的感情。 不过是想要得到偶像的认可罢了。 认可是自己给的，不要再傻了。 加油吧！ 最后，真好，我还有这一方自由乐园。"},{"title":"littletalk","date":"2020-09-14T03:58:28.000Z","updated":"2020-09-17T03:04:46.763Z","comments":true,"path":"secret/littletalk.html","permalink":"https://ymyforever.netlify.app/secret/littletalk.html","excerpt":"也许这就是偶像吧。每一次新的发现都能给我很大的精神震撼。 我一直以为庸人才应当在规则中生活，我这种疯子才应当指定规则。 人生短暂，我们来不及循规蹈矩。 我的生活永远与众不同。 这是多么狂妄自大的话啊，从我认识的其他任何一个人嘴里说出来都显得如此违和，只有你，你配得上这句话。","text":"也许这就是偶像吧。每一次新的发现都能给我很大的精神震撼。 我一直以为庸人才应当在规则中生活，我这种疯子才应当指定规则。 人生短暂，我们来不及循规蹈矩。 我的生活永远与众不同。 这是多么狂妄自大的话啊，从我认识的其他任何一个人嘴里说出来都显得如此违和，只有你，你配得上这句话。 我是一个在规则内循规蹈矩惯了的人，甚至利用规则谋求自己的利益。也是为了父母的规则，因为恐惧，恐惧父母得知女儿竟然和女生搅在一起时，那对我是灭顶之灾。 所以我选择了放弃，长痛不如短痛的放弃。我还爱吗？我告诉自己不爱了。 大学两年来，碌碌无为，既没有增长专业知识，也没有做出什么了不起的事情。我只是校园里千万颗齿轮里的一个，大齿轮，小齿轮，都是齿轮而已。 仰山之高，往往自惭形秽。可是功夫没到家，你没有资格。 对自己狠一点，再狠一点，你想要的，没人会给你，除了自己。 成为盖世英雄，而不要傻傻在原地等着。 你要的认可与肯定，只有自己能给你。 循此苦旅，循此苦旅。"},{"title":"tags","date":"2022-08-14T01:55:25.992Z","updated":"2022-08-14T01:55:25.992Z","comments":false,"path":"tags/index.html","permalink":"https://ymyforever.netlify.app/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"论文阅读：PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer","slug":"论文阅读：PhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer","date":"2022-09-15T02:12:07.000Z","updated":"2022-09-19T03:40:36.913Z","comments":true,"path":"2022/09/15/论文阅读：PhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/","link":"","permalink":"https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/","excerpt":"","text":"发表时间：2021 研究对象：rPPG，使用多波长 RGB 相机检测人体皮肤表面脉冲引起的细微颜色变化，实现测量心脏活动和其它生理信号。 研究意义：传统的检测方法会造成discomfort，并且长期检测不方便 Code：https://github.com/ZitongYu/PhysFormer rPPG研究历史： 早期使用经典的信号处理方法检测面部细微的颜色变化； 使用非端到端方法，首先生成预处理的信号特征，然后模型从这些特征图中捕捉rPPG特征（对预处理要求严格，忽略了全局特征）； 端到端的基于深度学习的方法（容易被复杂的背景信息影响）。 研究现状： ​ 现有的基于卷积神经网络的模型在时间和空间上的感受野受限，忽略了长期的时间和空间上的互动与感知。 PhysFormer网络架构： Stem：提取粗糙的局部时空特征 Tube Tokens：将stem输出划分为若干个时空tube token，将时空邻近语义聚合在一起，并减少后续transformer的计算量 Temporal Difference Multi-head Self-attention：与传统的自注意力机制不同，使用TDC计算距离，可以捕捉局部细粒度的时间差异特征 Spatio-temporal Feed-forward： 创新点：PhysFormer，一种端到端的视频transformer，联合使用了局部的和全局的时空特征。 使用时差引导全局注意力机制，强化rPPG的周期性特征，针对干扰完善局部时空特征； 使用受label distribution learning和curriculum learning启发的频域动态约束，为PhysFormer提供详细的监督，缓解过拟合。 PhysFormer不需要像其它transformer网络那样在大规模数据集上预训练，仅在rPPG数据集训练即可。 Label Distribution Learning：对于面部的rPPG信号，心率相近的视频会有相似的周期性特征。为了使得模型学习到这种特征，将心率估计问题看作一个多分类问题，有多少个心率就有多少类别，类别概率向量由高斯分布组成。 Curriculum Learning Guided Dynamic Loss：课程式学习是指模型从容易样本开始学习，逐步学习困难样本。在该任务中，从时域和频域两个方面限制模型学习，时域的限制更直接更容易学习，频域的限制较难学习，因此，使用动态的loss函数，逐步提高频域loss的比例。 实验：不同模型的对比实验、消融实验 Others：注意力图可视化","categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"},{"name":"PPG","slug":"PPG","permalink":"https://ymyforever.netlify.app/tags/PPG/"}]},{"title":"论文阅读：Model Behavior Preserving for Class-Incremental Learning","slug":"论文阅读：Model-Behavior-Preserving-for-Class-Incremental-Learning","date":"2022-08-23T02:45:11.000Z","updated":"2022-08-26T01:43:14.413Z","comments":true,"path":"2022/08/23/论文阅读：Model-Behavior-Preserving-for-Class-Incremental-Learning/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/23/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AModel-Behavior-Preserving-for-Class-Incremental-Learning/","excerpt":"","text":"发表时间：2022 研究内容：类增量学习，探讨在增量学习中应保留旧模型的哪些功能性属性。 研究现状：现有的增量学习方法忽略了CNN模型响应间的内部结构，KD的硬约束导致新模型出现混沌行为。 创新点： Feature Space：设计了一个INP Loss保持成对实例在旧模型上的相似性顺序（反映实例集间的相邻关系）； INP用于惩罚新模型在学习过程中每个实例相邻关系的变化。 a. 旧实例A在特征空间中与其它实例的相邻关系； b. 采用传统的KD，引入新实例G后，绝对位置的微小变化被严格限制； c. 采用INP Loss当相对位置没变时，就不会限制更新。 Label Space：设计了一个LPP Loss在输出空间的实例标签概率向量中保留标签排名列表（反映实例属于每一类的排名）； 介绍了一种可导的排名计算方法用于计算上述Loss。","categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读：Structural Knowledge Organization and Transfer for Class-Incremental Learning","slug":"论文阅读：Structural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning","date":"2022-08-21T08:05:32.000Z","updated":"2022-08-23T02:20:35.961Z","comments":true,"path":"2022/08/21/论文阅读：Structural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AStructural-Knowledge-Organization-and-Transfer-for-Class-Incremental-Learning/","excerpt":"","text":"发表时间：2021 研究问题：类增量学习 研究现状： 经典的知识蒸馏方法忽略了信息点之间的关联，当新数据远多于旧数据时，面临着严重的偏差问题； KD：在特征空间中，孤立地限制单个训练样本的位置，样本间的关系可能会被改变，并导致分类错误。 SGKD：保持样本的结构化知识，包括样本的位置和样本间关系，确保蒸馏后样本仍能被正确地分类。 创新点： 使用一个memory knowledge graph(MKG)表征历史任务的结构化知识 在特征空间中的绝对位置（MKG中用顶点表示已知example间的特征向量） example间对应关系（边表示，使用余弦距离） 使用图插值机制丰富知识域、缓解类间样本不平衡问题 通过向MKG中插入假的顶点，扩充和平滑分散的数据集，假顶点通过mix两个真顶点的vector得到。 使用结构化图知识蒸馏（SGKD）迁移旧知识 顶点蒸馏损失 边蒸馏损失 人脸识别是怎么实现增加新样本的？ 人脸识别网络的本质是一个特征提取器，并不是分类器，识别人脸的时候，通过计算输出特征和人脸库中人脸的距离判断人脸所属对象。未涉及类增量学习。","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读：IDPT, Interconnected Dual Pyramid Transformer for Face Super-Resolution","slug":"论文阅读：IDPT","date":"2022-08-14T01:31:37.000Z","updated":"2022-08-21T08:00:59.719Z","comments":true,"path":"2022/08/14/论文阅读：IDPT/","link":"","permalink":"https://ymyforever.netlify.app/2022/08/14/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AIDPT/","excerpt":"","text":"研究问题：人脸超分辨率技术 FSR：关注于恢复重要的面部结构 创新点：提出了一个新的、有效的基于Transformer的人脸超分辨率架构 设计了金字塔结构的encode&#x2F;decoder的Transformer架构：分别提取粗糙纹理和精细纹理。 通过一个底部的金字塔特征提取器，将双重金字塔Transformer建立起联系。 在每个spatial layer插入一个新的融合调制模块：使用粗糙纹理完善对应的精细纹理，融合浅层的粗糙纹理和对应的深层的精细纹理。 FSR研究现状 现有技术在解决超低分辨率问题上表现很差 卷积难以描述不同域间的关联和捕捉远域间的依赖 网络结构：","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"FSR","slug":"FSR","permalink":"https://ymyforever.netlify.app/tags/FSR/"},{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"}]},{"title":"HelloWorld!","slug":"HelloWorld","date":"2020-08-29T08:06:44.000Z","updated":"2022-08-13T09:48:18.595Z","comments":true,"path":"2020/08/29/HelloWorld/","link":"","permalink":"https://ymyforever.netlify.app/2020/08/29/HelloWorld/","excerpt":"","text":"A new world!哈喽！历经一个下午博客终于搭建好了，原来是那么容易的一件事情，大一的时候想的很复杂，迟迟没能动手，现在也终于有了自己的小博客啦~ 未来灌水的文章还是会首先发在CSDN上，这里会分享一些重大的经历~已经大三了！要更努力学习！不要被些奇奇怪怪的事情干扰，奥里给！","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"组内文章","slug":"组内文章","permalink":"https://ymyforever.netlify.app/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/"},{"name":"Transformer","slug":"Transformer","permalink":"https://ymyforever.netlify.app/tags/Transformer/"},{"name":"PPG","slug":"PPG","permalink":"https://ymyforever.netlify.app/tags/PPG/"},{"name":"连续学习","slug":"连续学习","permalink":"https://ymyforever.netlify.app/tags/%E8%BF%9E%E7%BB%AD%E5%AD%A6%E4%B9%A0/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://ymyforever.netlify.app/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"FSR","slug":"FSR","permalink":"https://ymyforever.netlify.app/tags/FSR/"}]}