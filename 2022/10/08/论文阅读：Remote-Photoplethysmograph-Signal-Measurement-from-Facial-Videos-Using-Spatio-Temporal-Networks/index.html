<!DOCTYPE html>
<html  lang="zh-CN" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>论文阅读：Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks | ymy is watching u!!!!</title>
    <meta name="description" content="发表时间：2019 code：https:&#x2F;&#x2F;github.com&#x2F;ZitongYu&#x2F;PhysNet HRV：Heart Rate Variability，心率变异性，从更精细的角度描述心脏活动 AF：atrial fibrillatio，心房震颤 时空网络：主流的时空网络有两种，第一种是基于3D卷积的时空网络，第二种是基于RNN的神经网络（如LSTM等）。  简介 文章提出了一个深度时空网络P">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks">
<meta property="og:url" content="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/index.html">
<meta property="og:site_name" content="ymy is watching u!!!!">
<meta property="og:description" content="发表时间：2019 code：https:&#x2F;&#x2F;github.com&#x2F;ZitongYu&#x2F;PhysNet HRV：Heart Rate Variability，心率变异性，从更精细的角度描述心脏活动 AF：atrial fibrillatio，心房震颤 时空网络：主流的时空网络有两种，第一种是基于3D卷积的时空网络，第二种是基于RNN的神经网络（如LSTM等）。  简介 文章提出了一个深度时空网络P">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008100615766.png">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008105124878.png">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008111446331.png">
<meta property="og:image" content="https://ymyforever.netlify.app/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221010183747585.png">
<meta property="article:published_time" content="2022-10-08T01:04:24.000Z">
<meta property="article:modified_time" content="2022-10-10T11:09:27.866Z">
<meta property="article:author" content="ymy">
<meta property="article:tag" content="rPPG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008100615766.png">

    
    <link rel="icon" href="/images.fvicon.ico" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.3.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/ymy-forever" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="/images/logo.png" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">ymy_forever</h2>
            <h3 id="title" class="hidden lg:block">Student &amp; Coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Xian, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="搜索" class="inline-block w-full bg-gray-100 lg:bg-white p-1">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="搜索" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="搜索" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">首页</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">归档</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">标签</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">关于</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            
    
        <h1 class="article-title text-lg" itemprop="name">
            论文阅读：Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks
        </h1>
    



            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/" class="article-date">
	  <time datetime="2022-10-08T01:04:24.000Z" itemprop="datePublished">10月 8</time>
	</a>
</span>

                

                
    <span class="article-tags">
    <i class="iconfont icon-tag"></i>
    <a class="article-tag-none-link" href="/tags/rPPG/" rel="tag">rPPG</a>
  </span>


                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/#comments" class="article-comment-link">
                        评论
                    </a>
                </span>
                
    
        <span class="post-wordcount" itemprop="wordCount">字数统计: 1.4k(字)</span>
    
    
        <span class="post-readcount" itemprop="timeRequired">阅读时长: 5(分)</span>
    


            </p>
        </header>
        <div class="marked-body article-body">
            <ul>
<li>发表时间：2019</li>
<li>code：<a target="_blank" rel="noopener" href="https://github.com/ZitongYu/PhysNet">https://github.com/ZitongYu/PhysNet</a></li>
<li>HRV：Heart Rate Variability，心率变异性，从更精细的角度描述心脏活动</li>
<li>AF：atrial fibrillatio，心房震颤</li>
<li>时空网络：主流的时空网络有两种，第一种是基于3D卷积的时空网络，第二种是基于RNN的神经网络（如LSTM等）。</li>
</ul>
<h2 id="简介">简介</h2>
<p>文章提出了一个深度时空网络PhysNet，用于从原始面部视频中重建精确的rPPG信号，包括每个时间位置与其对应的脉冲峰值，可以获得平均HR，以及HRV和IBIs信息，用于AF检测与情绪识别中。</p>
<h3 id="研究现状">研究现状</h3>
<ol>
<li>早期使用两阶段的方法，阶段1检测或跟踪面部以提取rPPG信号，阶段2通过频率分析估计对应的平均心率。但这种方法有两个缺点，1是自定义的面部区域是根据经验知识得到的，可能并非最佳的区域。2是该方法需要手工特征或过滤器，可能泛化能力弱并且丢失与心率相关的重要信息；</li>
<li>对于基于深度学习的心率检测方法，通常有如下几个缺点，1是将心率估计问题看作简单的一阶段回归问题，得到平均心率，而丢失了单个脉冲峰值信息，从而限制了在医学上的应用；2是使用的方法并非端到端的系统，仍然需要预处理或后处理步骤，引入了手工特征；3是使用的方法基于2D空间神经网络，没有考虑对rPPG测量重要的时间特征。</li>
</ol>
<h3 id="模型简介">模型简介</h3>
<p>文章提出的rPPG信号测量方法的框架如下图所示：</p>
<img src="/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008100615766.png" alt="image-20221008100615766" style="zoom:80%; margin:auto;">
<p>文章的主要贡献包括如下几点：</p>
<ol>
<li>提出了第一个基于端到端的rPPG信号测量网络PhysNet，并将之前忽略的时间信息考虑进去；</li>
<li>PhysNet在测量平均心率和HRV特征上都达到了很好的性能；</li>
<li>PhysNet具有很好的泛化性</li>
</ol>
<h2 id="PhysNet">PhysNet</h2>
<p>PhysNet的结构如下图所示：</p>
<img src="/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008105124878.png" alt="image-20221008105124878" style="zoom:80%; margin:auto;">
<p>主流的时空网络有基于3DCNN和基于RNN两种，因此作者也提出了两种PhyNet。</p>
<h3 id="3DCNN-based-PhysNet">3DCNN based PhysNet</h3>
<ul>
<li>采用一个3x3x3的卷积在空间域和时间域同时提取rPPG特征。</li>
<li>采用基于时间的encoder-decoder结构PhysNet-3DCNN-ED，可以更有效地利用时间信息，减少冗余与噪音。</li>
</ul>
<h3 id="RNN-based-PhysNet">RNN based PhysNet</h3>
<ul>
<li>首先使用2DCNN提取空间特征，然后使用基于RNN的模块实现空间特征在时域的传播</li>
</ul>
<h3 id="损失函数">损失函数</h3>
<p>使用负皮尔森相关系数作为损失函数，以最大化趋势相似度，最小化峰值定位误差。</p>
<img src="/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/image-20221008111446331.png" alt="image-20221008111446331" style="zoom: 50%; margin:auto;">
<h2 id="实验设置">实验设置</h2>
<h3 id="数据集">数据集</h3>
<p>文章使用了两个数据集，使用OBF数据集进行训练与测试，使用MAHNOB-HCI数据集进行模型泛化能力的交叉验证。</p>
<ol>
<li>OBF数据集：采集自100个健康的成人和6个患有心房震颤的病人，每个人有两个时长为5分钟的视频，每个视频包括其对应的ECG、呼吸、ppg信号，每个视频的分辨率为1920x2080，帧率为60fps。</li>
<li>MAHNOB-HCI数据集：采集自27个人的共527个视频，每个视频的分辨率为780x580，帧率为61fps。</li>
</ol>
<h3 id="训练设置">训练设置</h3>
<p>对于每一个视频，进行如下操作：</p>
<ul>
<li>在第一帧中使用Viola-Jones面部检测器切割出面部区域，并在之后的帧中固定这个区域；</li>
<li>将面部图片正则化到128x128</li>
<li>将视频和对应的真实信号进行下采样，视频下采样至30fps，信号下采样至30HZ</li>
<li>使用Adam，lr=1e-4，epoch=15</li>
</ul>
<h3 id="测试设置">测试设置</h3>
<p>对于HR与HRV的评估，使用如下几个性能指标：</p>
<ol>
<li>SD（standard deviation）：标准差</li>
<li>RMSE（root mean square error）：均方根误差</li>
<li>R（Pearson’s correlation coefficien）：皮尔森相关系数</li>
<li>MAE（mean absolute error）：平均绝对误差</li>
</ol>
<h2 id="代码实现（UBFC版）">代码实现（UBFC版）</h2>
<h3 id="数据集UBFC-rPPG">数据集UBFC-rPPG</h3>
<p><strong>UBFC-rPPG</strong>：出自论文《Unsupervised skin tissue segmentation for remote photoplethysmography》</p>
<ul>
<li>
<p>video：43个</p>
</li>
<li>
<p>time：2min</p>
</li>
<li>
<p>帧率：30fps</p>
</li>
<li>
<p>分辨率：640x480</p>
</li>
<li>
<p>ground truth：与视频同步的心率信号，对于ground truth，第一行是gtTrace，第二行是gtHR，第三行是gtTime。</p>
<img src="/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221010183747585.png" alt="image-20221010183747585" style="zoom:80%;">
</li>
</ul>
<h3 id="K-交叉验证（但好像没用到）">K-交叉验证（但好像没用到）</h3>
<p>K-交叉验证是一种<strong>模型评估</strong>方法，指将原始数据均分成k组，轮流将每个子集数据分别作为验证集，其余k-1组子集数据作为训练集，这样将得到k个模型，用k个模型的平均性能作为模型的评价指标。</p>
<h3 id="DataLoader">DataLoader</h3>
<p>PhysNet实现中，训练集和测试集是通过如下代码手动划分的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (test):</span><br><span class="line">    self.vdPath_list = os.listdir(<span class="string">&quot;/data/maoguanhui/UBFC/&quot;</span>)[<span class="number">30</span>:<span class="number">42</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    self.vdPath_list = os.listdir(<span class="string">&quot;/data/maoguanhui/UBFC/&quot;</span>)[:<span class="number">30</span>]</span><br></pre></td></tr></table></figure>
<p>之后，将每个视频划分为7个片段，每个片段包括160帧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clip = idx % <span class="number">7</span>  <span class="comment"># 第几个剪辑片段</span></span><br><span class="line">idx = <span class="built_in">int</span>(idx / <span class="number">7</span>)  <span class="comment"># 第几个视频</span></span><br><span class="line">start_frame = <span class="number">160</span> * clip</span><br></pre></td></tr></table></figure>
<p>然后从ground truth中获取计算loss需要的信息，首先获取平均HR，用于计算师兄添加的fre_loss</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">clhr = <span class="built_in">list</span>(data[<span class="number">1</span>].split())</span><br><span class="line">clhr = [<span class="built_in">str</span>.replace(<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;E&#x27;</span>) <span class="keyword">for</span> <span class="built_in">str</span> <span class="keyword">in</span> clhr]</span><br><span class="line">sumHR = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> kj <span class="keyword">in</span> <span class="built_in">range</span>(start_frame, start_frame + <span class="number">160</span>):</span><br><span class="line">    sumHR += <span class="built_in">float</span>(clhr[kj])</span><br><span class="line">clip_average_HR = sumHR / <span class="number">160</span></span><br></pre></td></tr></table></figure>
<p>再获取PPG信号，用于计算皮尔森系数对应的rPPG loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Trace = []</span><br><span class="line">data = <span class="built_in">list</span>(data[<span class="number">0</span>].split())</span><br><span class="line">data = [<span class="built_in">str</span>.replace(<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;E&#x27;</span>) <span class="keyword">for</span> <span class="built_in">str</span> <span class="keyword">in</span> data]</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">    Trace.append(<span class="built_in">float</span>(data[j]))</span><br></pre></td></tr></table></figure>
<h3 id="网络结构">网络结构</h3>
<p>在PhysNet的网络实现中，有多种网络，文章中选择使用PhysNet_padding_ED_peak</p>

        </div>
        
<blockquote class="copyright">
    <p><strong>本文链接 : </strong><a class="permalink" href="https://ymyforever.netlify.app/2022/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ARemote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/">https://ymyforever.netlify.app/2022/10/08/论文阅读：Remote-Photoplethysmograph-Signal-Measurement-from-Facial-Videos-Using-Spatio-Temporal-Networks/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">文章目录</h3>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6"><span class="toc-number">1.1.</span> <span class="toc-text">研究现状</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.</span> <span class="toc-text">模型简介</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PhysNet"><span class="toc-number">2.</span> <span class="toc-text">PhysNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3DCNN-based-PhysNet"><span class="toc-number">2.1.</span> <span class="toc-text">3DCNN based PhysNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RNN-based-PhysNet"><span class="toc-number">2.2.</span> <span class="toc-text">RNN based PhysNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.3.</span> <span class="toc-text">损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">实验设置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.2.</span> <span class="toc-text">训练设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.3.</span> <span class="toc-text">测试设置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%88UBFC%E7%89%88%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">代码实现（UBFC版）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86UBFC-rPPG"><span class="toc-number">4.1.</span> <span class="toc-text">数据集UBFC-rPPG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#K-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%88%E4%BD%86%E5%A5%BD%E5%83%8F%E6%B2%A1%E7%94%A8%E5%88%B0%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">K-交叉验证（但好像没用到）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataLoader"><span class="toc-number">4.3.</span> <span class="toc-text">DataLoader</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">4.4.</span> <span class="toc-text">网络结构</span></a></li></ol></li></ol>
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
