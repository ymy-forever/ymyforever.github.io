<!DOCTYPE html>
<html  lang="zh-CN" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>论文阅读：PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer | ymy is watching u!!!!</title>
    <meta name="description" content="发表时间：2021  研究对象：rPPG，使用多波长 RGB 相机检测人体皮肤表面脉冲引起的细微颜色变化，实现测量心脏活动和其它生理信号。  研究意义：传统的检测方法会造成discomfort，并且长期检测不方便  Code：https:&#x2F;&#x2F;github.com&#x2F;ZitongYu&#x2F;PhysFormer  rPPG研究历史：  早期使用经典的信号处理方法检测面部细微的颜色变化； 使用非端到端方法，">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer">
<meta property="og:url" content="https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/index.html">
<meta property="og:site_name" content="ymy is watching u!!!!">
<meta property="og:description" content="发表时间：2021  研究对象：rPPG，使用多波长 RGB 相机检测人体皮肤表面脉冲引起的细微颜色变化，实现测量心脏活动和其它生理信号。  研究意义：传统的检测方法会造成discomfort，并且长期检测不方便  Code：https:&#x2F;&#x2F;github.com&#x2F;ZitongYu&#x2F;PhysFormer  rPPG研究历史：  早期使用经典的信号处理方法检测面部细微的颜色变化； 使用非端到端方法，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/image-20220919092041506.png">
<meta property="og:image" content="https://ymyforever.netlify.app/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170008240.png">
<meta property="og:image" content="https://ymyforever.netlify.app/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170042081.png">
<meta property="og:image" content="https://ymyforever.netlify.app/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170158926.png">
<meta property="article:published_time" content="2022-09-15T02:12:07.000Z">
<meta property="article:modified_time" content="2022-10-04T02:47:21.189Z">
<meta property="article:author" content="ymy">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="组内文章">
<meta property="article:tag" content="rPPG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/image-20220919092041506.png">

    
    <link rel="icon" href="/images.fvicon.ico" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.3.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/ymy-forever" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="/images/logo.png" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">ymy_forever</h2>
            <h3 id="title" class="hidden lg:block">Student &amp; Coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Xian, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="搜索" class="inline-block w-full bg-gray-100 lg:bg-white p-1">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="搜索" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="搜索" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">首页</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">归档</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">标签</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">关于</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            
    
        <h1 class="article-title text-lg" itemprop="name">
            论文阅读：PhysFormer: Facial Video-based Physiological Measurement with Temporal Difference Transformer
        </h1>
    



            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/" class="article-date">
	  <time datetime="2022-09-15T02:12:07.000Z" itemprop="datePublished">9月 15</time>
	</a>
</span>

                

                
    <span class="article-tags">
    <i class="iconfont icon-tag"></i>
    <a class="article-tag-none-link" href="/tags/Transformer/" rel="tag">Transformer</a>, <a class="article-tag-none-link" href="/tags/rPPG/" rel="tag">rPPG</a>, <a class="article-tag-none-link" href="/tags/%E7%BB%84%E5%86%85%E6%96%87%E7%AB%A0/" rel="tag">组内文章</a>
  </span>


                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/#comments" class="article-comment-link">
                        评论
                    </a>
                </span>
                
    
        <span class="post-wordcount" itemprop="wordCount">字数统计: 2k(字)</span>
    
    
        <span class="post-readcount" itemprop="timeRequired">阅读时长: 9(分)</span>
    


            </p>
        </header>
        <div class="marked-body article-body">
            <ul>
<li><p>发表时间：2021</p>
</li>
<li><p>研究对象：rPPG，使用多波长 RGB 相机检测人体皮肤表面脉冲引起的细微颜色变化，实现测量心脏活动和其它生理信号。</p>
</li>
<li><p>研究意义：传统的检测方法会造成discomfort，并且长期检测不方便</p>
</li>
<li><p>Code：<a target="_blank" rel="noopener" href="https://github.com/ZitongYu/PhysFormer">https://github.com/ZitongYu/PhysFormer</a></p>
</li>
<li><p>rPPG研究历史：</p>
<ol>
<li>早期使用经典的信号处理方法检测面部细微的颜色变化；</li>
<li>使用非端到端方法，首先生成预处理的信号特征，然后模型从这些特征图中捕捉rPPG特征（对预处理要求严格，忽略了全局特征）；</li>
<li>端到端的基于深度学习的方法（容易被复杂的背景信息影响）。</li>
</ol>
</li>
<li><p>研究现状：</p>
<p>​		现有的基于卷积神经网络的模型在时间和空间上的感受野受限，忽略了长期的时间和空间上的互动与感知。</p>
</li>
<li><p>PhysFormer网络架构：</p>
<img src="/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/image-20220919092041506.png" alt="image-20220919092041506" style="zoom:80%;">

<ol>
<li><p><strong>Stem</strong>：由三个卷积块组成，用于提取粗糙的局部时空特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># INPUT:[B,3,T,H,W]</span></span><br><span class="line"><span class="comment"># OUTPUT:[B,D,T,H/8,W/8]</span></span><br><span class="line"><span class="comment"># use</span></span><br><span class="line">x = self.Stem0(x)</span><br><span class="line">x = self.Stem1(x)</span><br><span class="line">x = self.Stem2(x)  <span class="comment"># [B, 64, 160, 64, 64]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># implement</span></span><br><span class="line">self.Stem0 = nn.Sequential(</span><br><span class="line">    nn.Conv3d(<span class="number">3</span>, dim//<span class="number">4</span>, [<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>], stride=<span class="number">1</span>, padding=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>]),</span><br><span class="line">    nn.BatchNorm3d(dim//<span class="number">4</span>),</span><br><span class="line">    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">    nn.MaxPool3d((<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">self.Stem1 = nn.Sequential(</span><br><span class="line">    nn.Conv3d(dim//<span class="number">4</span>, dim//<span class="number">2</span>, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.BatchNorm3d(dim//<span class="number">2</span>),</span><br><span class="line">    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">    nn.MaxPool3d((<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">self.Stem2 = nn.Sequential(</span><br><span class="line">    nn.Conv3d(dim//<span class="number">2</span>, dim, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.BatchNorm3d(dim),</span><br><span class="line">    nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">    nn.MaxPool3d((<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Tube Tokens</strong>：将stem输出划分为若干个时空tube token，将时空邻近语义聚合在一起，并减少后续transformer的计算量。通过一个3D卷积实现。</p>
<p>tip：在嵌入后没有额外加上位置编码，因为在stem里已经捕捉了相关的时空信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># INPUT: # [B, 64, 160, 64, 64] ([B,D,T,H/8,W/8])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use</span></span><br><span class="line">x = self.patch_embedding(x)  <span class="comment"># [B, 64, 40, 4, 4]</span></span><br><span class="line">x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 40*4*4, 64](B,N,D)</span></span><br><span class="line"><span class="comment"># implement</span></span><br><span class="line"><span class="comment"># Patch embedding    [4x16x16]conv</span></span><br><span class="line">self.patch_embedding = nn.Conv3d(dim, dim, kernel_size=(ft, fh, fw), stride=(ft, fh, fw))</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Temporal Difference Multi-head Self-attention</strong>：</p>
<p>与传统的自注意力机制不同，使用TDC（Temporal Difference Convolution）查询Q和K的投影，可以捕捉局部细粒度的时间差异特征。</p>
<img src="/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170008240.png" alt="image-20221002170008240" style="zoom:80%; margin:auto;">

<img src="/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170042081.png" alt="image-20221002170042081" style="zoom: 67%; margin:auto;">

<img src="/C:/Users/zxkj/AppData/Roaming/Typora/typora-user-images/image-20221002170158926.png" alt="image-20221002170158926" style="zoom:67%; margin:auto;">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多头自注意力机制实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadedSelfAttention_TDC_gra_sharp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multi-Headed Dot Product Attention with depth-wise Conv3d&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, dropout, theta</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.proj_q = nn.Sequential(</span><br><span class="line">            CDC_T(dim, dim, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">False</span>, theta=theta),  </span><br><span class="line">            nn.BatchNorm3d(dim),</span><br><span class="line">            <span class="comment">#nn.ELU(),</span></span><br><span class="line">        )</span><br><span class="line">        self.proj_k = nn.Sequential(</span><br><span class="line">            CDC_T(dim, dim, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">False</span>, theta=theta),  </span><br><span class="line">            nn.BatchNorm3d(dim),</span><br><span class="line">            <span class="comment">#nn.ELU(),</span></span><br><span class="line">        )</span><br><span class="line">        self.proj_v = nn.Sequential(</span><br><span class="line">            nn.Conv3d(dim, dim, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, groups=<span class="number">1</span>, bias=<span class="literal">False</span>),  </span><br><span class="line">            <span class="comment">#nn.BatchNorm3d(dim),</span></span><br><span class="line">            <span class="comment">#nn.ELU(),</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.drop = nn.Dropout(dropout)</span><br><span class="line">        self.n_heads = num_heads</span><br><span class="line">        self.scores = <span class="literal">None</span> <span class="comment"># for visualization</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, gra_sharp</span>):    <span class="comment"># [B, 4*4*40, 128]</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        x, q(query), k(key), v(value) : (B(batch_size), S(seq_len), D(dim))</span></span><br><span class="line"><span class="string">        mask : (B(batch_size) x S(seq_len))</span></span><br><span class="line"><span class="string">        * split D(dim) into (H(n_heads), W(width of head)) ; D = H * W</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># (B, S, D) -proj-&gt; (B, S, D) -split-&gt; (B, S, H, W) -trans-&gt; (B, H, S, W)</span></span><br><span class="line">        </span><br><span class="line">        [B, P, C]=x.shape</span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).view(B, C, P//<span class="number">16</span>, <span class="number">4</span>, <span class="number">4</span>)      <span class="comment"># [B, dim, 40, 4, 4]</span></span><br><span class="line">        q, k, v = self.proj_q(x), self.proj_k(x), self.proj_v(x)<span class="comment"># 由CDC计算得到Q和K，3D卷积得到V</span></span><br><span class="line">        q = q.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 4*4*40, dim]</span></span><br><span class="line">        k = k.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 4*4*40, dim]</span></span><br><span class="line">        v = v.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 4*4*40, dim]</span></span><br><span class="line">        </span><br><span class="line">        q, k, v = (split_last(x, (self.n_heads, -<span class="number">1</span>)).transpose(<span class="number">1</span>, <span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> [q, k, v])</span><br><span class="line">        <span class="comment"># (B, H, S, W) @ (B, H, W, S) -&gt; (B, H, S, S) -softmax-&gt; (B, H, S, S)</span></span><br><span class="line">        scores = q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>) / gra_sharp<span class="comment"># 矩阵相乘，计算得分（权重）</span></span><br><span class="line">		<span class="comment"># tip：在python里，“@”表示数学上的矩阵相乘，“*”表示矩阵对应位置两元素相乘</span></span><br><span class="line">        </span><br><span class="line">        scores = self.drop(F.softmax(scores, dim=-<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># (B, H, S, S) @ (B, H, S, W) -&gt; (B, H, S, W) -trans-&gt; (B, S, H, W)</span></span><br><span class="line">        h = (scores @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous()<span class="comment"># 计算结果</span></span><br><span class="line">        <span class="comment"># -merge-&gt; (B, S, D)</span></span><br><span class="line">        h = merge_last(h, <span class="number">2</span>)</span><br><span class="line">        self.scores = scores</span><br><span class="line">        <span class="keyword">return</span> h, scores</span><br><span class="line"><span class="comment"># TDC</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CDC_T</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 padding=<span class="number">1</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">False</span>, theta=<span class="number">0.6</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(CDC_T, self).__init__()</span><br><span class="line">        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,                                   padding=padding, dilation=dilation, groups=groups, bias=bias)</span><br><span class="line">        self.theta = theta</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out_normal = self.conv(x)<span class="comment"># 正常3D卷积输出</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> math.fabs(self.theta - <span class="number">0.0</span>) &lt; <span class="number">1e-8</span>:</span><br><span class="line">            <span class="keyword">return</span> out_normal</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># pdb.set_trace()</span></span><br><span class="line">            [C_out, C_in, t, kernel_size, kernel_size] = self.conv.weight.shape</span><br><span class="line"></span><br><span class="line">            <span class="comment"># only CD works on temporal kernel size&gt;1</span></span><br><span class="line">            <span class="keyword">if</span> self.conv.weight.shape[<span class="number">2</span>] &gt; <span class="number">1</span>:</span><br><span class="line">                kernel_diff = self.conv.weight[:, :, <span class="number">0</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>) + self.conv.weight[:, :,                               <span class="number">2</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>)</span><br><span class="line">                kernel_diff = kernel_diff[:, :, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">                <span class="comment"># 时间差异项</span></span><br><span class="line">                out_diff = F.conv3d(<span class="built_in">input</span>=x, weight=kernel_diff, bias=self.conv.bias,                                                     stride=self.conv.stride, padding=<span class="number">0</span>, dilation=self.conv.dilation,                                     groups=self.conv.groups)</span><br><span class="line">                <span class="keyword">return</span> out_normal - self.theta * out_diff</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Spatio-temporal Feed-forward</strong>：在常用的两层线性transformation层之间，引入基于深度的3D卷积，ST-FF可以改善局部不一致性和部分噪声特征，同时丰富的局部性为TD-MHSA提供足够的相对位置信息，从而实现性能提升。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use</span></span><br><span class="line"><span class="comment"># Transformer</span></span><br><span class="line">self.transformer1 = Transformer_ST_TDC_gra_sharp(num_layers=num_layers//<span class="number">3</span>, dim=dim, 		                             num_heads=num_heads, ff_dim=ff_dim, dropout=dropout_rate, theta=theta)</span><br><span class="line"><span class="comment"># Transformer</span></span><br><span class="line">self.transformer2 = Transformer_ST_TDC_gra_sharp(num_layers=num_layers//<span class="number">3</span>, dim=dim,                                       num_heads=num_heads, ff_dim=ff_dim, dropout=dropout_rate, theta=theta)</span><br><span class="line"><span class="comment"># Transformer</span></span><br><span class="line">self.transformer3 = Transformer_ST_TDC_gra_sharp(num_layers=num_layers//<span class="number">3</span>, dim=dim,                                       num_heads=num_heads, ff_dim=ff_dim, dropout=dropout_rate, theta=theta)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer_ST_TDC_gra_sharp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transformer with Self-Attentive Blocks&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_layers, dim, num_heads, ff_dim, dropout, theta</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            Block_ST_TDC_gra_sharp(dim, num_heads, ff_dim, dropout, theta) <span class="keyword">for</span> _ <span class="keyword">in</span>                                                      <span class="built_in">range</span>(num_layers)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, gra_sharp</span>):</span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.blocks:</span><br><span class="line">            x, Score = block(x, gra_sharp)</span><br><span class="line">        <span class="keyword">return</span> x, Score</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block_ST_TDC_gra_sharp</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transformer Block&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, num_heads, ff_dim, dropout, theta</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attn = MultiHeadedSelfAttention_TDC_gra_sharp(dim, num_heads, dropout, theta)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)</span><br><span class="line">        self.norm1 = nn.LayerNorm(dim, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.pwff = PositionWiseFeedForward_ST(dim, ff_dim)<span class="comment"># ST-FF</span></span><br><span class="line">        self.norm2 = nn.LayerNorm(dim, eps=<span class="number">1e-6</span>)</span><br><span class="line">        self.drop = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, gra_sharp</span>):</span><br><span class="line">        Atten, Score = self.attn(self.norm1(x), gra_sharp)</span><br><span class="line">        h = self.drop(self.proj(Atten))</span><br><span class="line">        x = x + h</span><br><span class="line">        h = self.drop(self.pwff(self.norm2(x)))</span><br><span class="line">        x = x + h</span><br><span class="line">        <span class="keyword">return</span> x, Score</span><br><span class="line">    </span><br><span class="line"><span class="comment"># implement</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionWiseFeedForward_ST</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;FeedForward Neural Networks for each position&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, ff_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.fc1 = nn.Sequential(</span><br><span class="line">            nn.Conv3d(dim, ff_dim, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),  </span><br><span class="line">            nn.BatchNorm3d(ff_dim),</span><br><span class="line">            nn.ELU(),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.STConv = nn.Sequential(</span><br><span class="line">            nn.Conv3d(ff_dim, ff_dim, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, groups=ff_dim, bias=<span class="literal">False</span>),  </span><br><span class="line">            nn.BatchNorm3d(ff_dim),</span><br><span class="line">            nn.ELU(),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.fc2 = nn.Sequential(</span><br><span class="line">            nn.Conv3d(ff_dim, dim, <span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),  </span><br><span class="line">            nn.BatchNorm3d(dim),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):    <span class="comment"># [B, 4*4*40, 128]</span></span><br><span class="line">        [B, P, C]=x.shape</span><br><span class="line">        <span class="comment">#x = x.transpose(1, 2).view(B, C, 40, 4, 4)      # [B, dim, 40, 4, 4]</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).view(B, C, P//<span class="number">16</span>, <span class="number">4</span>, <span class="number">4</span>)      <span class="comment"># [B, dim, 40, 4, 4]</span></span><br><span class="line">        x = self.fc1(x)		              <span class="comment"># x [B, ff_dim, 40, 4, 4]</span></span><br><span class="line">        <span class="comment"># 使用时空卷积</span></span><br><span class="line">        x = self.STConv(x)		          <span class="comment"># x [B, ff_dim, 40, 4, 4]</span></span><br><span class="line">        x = self.fc2(x)		              <span class="comment"># x [B, dim, 40, 4, 4]</span></span><br><span class="line">        x = x.flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 4*4*40, dim]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># (B, S, D) -&gt; (B, S, D_ff) -&gt; (B, S, D)</span></span><br><span class="line">        <span class="comment">#return self.fc2(F.gelu(self.fc1(x)))</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>创新点：PhysFormer，一种端到端的视频transformer，联合使用了局部的和全局的时空特征。</p>
<ol>
<li>使用<strong>时差引导全局注意力机制</strong>，强化rPPG的周期性特征，针对干扰完善局部时空特征；</li>
<li>使用受label distribution learning和curriculum learning启发的频域动态约束，为PhysFormer提供详细的监督，缓解过拟合。</li>
<li>PhysFormer不需要像其它transformer网络那样在大规模数据集上预训练，仅在rPPG数据集训练即可。</li>
</ol>
</li>
<li><p><strong>Label Distribution Learning</strong>：对于面部的rPPG信号，心率相近的视频会有相似的周期性特征。为了使得模型学习到这种特征，将心率估计问题看作一个多分类问题，有多少个心率就有多少类别，类别概率向量由高斯分布组成。</p>
</li>
<li><p><strong>Curriculum Learning Guided Dynamic Loss</strong>：课程式学习是指模型从容易样本开始学习，逐步学习困难样本。在该任务中，从时域和频域两个方面限制模型学习，时域的限制更直接更容易学习，频域的限制较难学习，因此，使用动态的loss函数，逐步提高频域loss的比例。</p>
</li>
<li><p>实验：不同模型的对比实验、消融实验</p>
</li>
<li><p>Others：注意力图可视化</p>
</li>
</ul>

        </div>
        
<blockquote class="copyright">
    <p><strong>本文链接 : </strong><a class="permalink" href="https://ymyforever.netlify.app/2022/09/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/">https://ymyforever.netlify.app/2022/09/15/论文阅读：PhysFormer-Facial-Video-based-Physiological-Measurement-with-Temporal-Difference-Transformer/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">文章目录</h3>
            
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
