<!DOCTYPE html>
<html  lang="zh-CN" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>神经网络基础知识 | ymy is watching u!!!!</title>
    <meta name="description" content="3D CNN参考博客： ​        https:&#x2F;&#x2F;blog.csdn.net&#x2F;auto1993&#x2F;article&#x2F;details&#x2F;70948249 ​        https:&#x2F;&#x2F;blog.csdn.net&#x2F;YOULANSHENGMENG&#x2F;article&#x2F;details&#x2F;121328554 使用3D CNN可以捕获视频中的时间和空间的特征信息。 Conv3D3D卷积：对于下面的采用3D卷积">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络基础知识">
<meta property="og:url" content="https://ymyforever.netlify.app/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/index.html">
<meta property="og:site_name" content="ymy is watching u!!!!">
<meta property="og:description" content="3D CNN参考博客： ​        https:&#x2F;&#x2F;blog.csdn.net&#x2F;auto1993&#x2F;article&#x2F;details&#x2F;70948249 ​        https:&#x2F;&#x2F;blog.csdn.net&#x2F;YOULANSHENGMENG&#x2F;article&#x2F;details&#x2F;121328554 使用3D CNN可以捕获视频中的时间和空间的特征信息。 Conv3D3D卷积：对于下面的采用3D卷积">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdn.net/20170429133650515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-8ba548951eb9a627c45e67a654641576_720w.webp">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-c088862cb3f9790751f558ecac7b49c3_720w.webp">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/19293651-b1bbd94eaca4a61b.png?imageMogr2/auto-orient/strip|imageView2/2/w/496/format/webp">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/image-20221015151341198.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-6b6cbc16d5dd7fb0bc044b238e3a948f_720w.webp">
<meta property="og:image" content="https://ymyforever.netlify.app/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/image-20221015172029434.png">
<meta property="article:published_time" content="2022-09-27T09:31:15.000Z">
<meta property="article:modified_time" content="2022-10-25T07:24:22.131Z">
<meta property="article:author" content="ymy">
<meta property="article:tag" content="神经网络基础知识">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdn.net/20170429133650515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center">

    
    <link rel="icon" href="/images.fvicon.ico" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
        <link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet">
    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.3.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/ymy-forever" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="/images/logo.png" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">ymy_forever</h2>
            <h3 id="title" class="hidden lg:block">Student &amp; Coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Xian, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="搜索" class="inline-block w-full bg-gray-100 lg:bg-white p-1">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="搜索" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="搜索" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">首页</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">归档</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">标签</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">关于</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            
    
        <h1 class="article-title text-lg" itemprop="name">
            神经网络基础知识
        </h1>
    



            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="article-date">
	  <time datetime="2022-09-27T09:31:15.000Z" itemprop="datePublished">9月 27</time>
	</a>
</span>

                

                
    <span class="article-tags">
    <i class="iconfont icon-tag"></i>
    <a class="article-tag-none-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="tag">神经网络基础知识</a>
  </span>


                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/#comments" class="article-comment-link">
                        评论
                    </a>
                </span>
                
    
        <span class="post-wordcount" itemprop="wordCount">字数统计: 1.2k(字)</span>
    
    
        <span class="post-readcount" itemprop="timeRequired">阅读时长: 5(分)</span>
    


            </p>
        </header>
        <div class="marked-body article-body">
            <h2 id="3D-CNN"><a href="#3D-CNN" class="headerlink" title="3D CNN"></a>3D CNN</h2><p>参考博客：</p>
<p>​        <a target="_blank" rel="noopener" href="https://blog.csdn.net/auto1993/article/details/70948249">https://blog.csdn.net/auto1993/article/details/70948249</a></p>
<p>​        <a target="_blank" rel="noopener" href="https://blog.csdn.net/YOULANSHENGMENG/article/details/121328554">https://blog.csdn.net/YOULANSHENGMENG/article/details/121328554</a></p>
<p>使用3D CNN可以捕获视频中的<strong>时间</strong>和<strong>空间</strong>的特征信息。</p>
<h3 id="Conv3D"><a href="#Conv3D" class="headerlink" title="Conv3D"></a>Conv3D</h3><p>3D卷积：对于下面的采用3D卷积核进行的卷积操作，通过堆叠多个连续的帧组成一个立方体，在立方体中运用3D卷积核，卷积层中每一个特征map都与上一层中多个邻近的连续帧相连，以此捕捉运动信息。下图卷积操作的时间维度为3（对连续的三帧图像进行卷积操作）。</p>
<p><img src="https://img-blog.csdn.net/20170429133650515?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvQVVUTzE5OTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom:80%; margin:auto;"></p>
<p>tip：<strong>3D卷积核只能从cube中提取一种类型的特征</strong>（在整个cube中卷积核的权值是共享的），若要提取多种特征，可以采用多种卷积核。</p>
<p>在pytorch中，同样有Conv3D的实现，使用样例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample intput | 随机输入</span></span><br><span class="line"><span class="comment"># (batch_size, channel, fram_size, height, width)</span></span><br><span class="line">net_input = torch.randn(<span class="number">32</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有维度同一个参数配置</span></span><br><span class="line">conv = nn.Conv3d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">net_output = conv(net_input)</span><br><span class="line"><span class="built_in">print</span>(net_output.shape)  <span class="comment"># shape=[32, 64, 5, 112, 112] | 相当于每一个维度上的卷积核大小都是3，步长都是2，pad都是1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一维度不同参数配置</span></span><br><span class="line">conv = nn.Conv3d(<span class="number">3</span>, <span class="number">64</span>, (<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">net_output = conv(net_input)</span><br><span class="line"><span class="built_in">print</span>(net_output.shape) <span class="comment"># shape=[32, 64, 9, 112, 112]</span></span><br></pre></td></tr></table></figure>
<h2 id="差分卷积（Difference-Convolution）"><a href="#差分卷积（Difference-Convolution）" class="headerlink" title="差分卷积（Difference Convolution）"></a>差分卷积（Difference Convolution）</h2><p>参考博客：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/392986663">https://zhuanlan.zhihu.com/p/392986663</a></p>
<pre class="mermaid">graph LR
A[LBP]-->B[CDC]
B-->c[3D-CDC]</pre>

<p>空间差分特征具有如下两个优点：</p>
<ol>
<li>对于光照变化具有鲁棒性；</li>
<li>描述了细粒度的纹理信息。</li>
</ol>
<h3 id="LBP（Local-Binary-Patterns）"><a href="#LBP（Local-Binary-Patterns）" class="headerlink" title="LBP（Local Binary Patterns）"></a>LBP（Local Binary Patterns）</h3><p>LBP即局部二值模式，是一种经典的传统手工特征提取方法。</p>
<p>在3x3邻域，将周围像素点的灰度值与中心像素值进行比较，大于中心像素记为1，小于中心像素记为0。这样将产生8个二进制数，然后转换为十进制的LBP码，用LBP码反映该区域的纹理信息。</p>
<p><img src="https://pic3.zhimg.com/80/v2-8ba548951eb9a627c45e67a654641576_720w.webp" alt="img" style="zoom:100%; margin:auto;"></p>
<p>对于图像中的每个像素点，都对应一个LBP码，LBP码聚合了邻域内的差分信息，对光照变化较为鲁棒，同时描述了细粒度的纹理信息，早期在人脸识别中广泛使用。</p>
<h3 id="中心差分卷积（Central-Difference-Convolution）"><a href="#中心差分卷积（Central-Difference-Convolution）" class="headerlink" title="中心差分卷积（Central Difference Convolution）"></a>中心差分卷积（Central Difference Convolution）</h3><p>Q：为什么vanilla卷积不好使？</p>
<p>A：vanilla卷积是直接聚合局部的亮度级的信息，容易受到光照等因素影响，同时难以表征细粒度的特征。应用到活体检测任务中，受光照等因素影响会导致模型泛化能力变弱，难以表征细粒度的特征则会导致模型难以学到防伪本质的细节信息。根据上述描述，使用空间差分特征可以缓解vanilla卷积存在的问题。</p>
<p>CDC的工作原理如下图所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-c088862cb3f9790751f558ecac7b49c3_720w.webp" alt="img" style="zoom:100%; margin:auto;"></p>
<p>其数值形式的卷积过程如下所示，用区域内的像素与中心像素作差值，然后再进行卷积操作。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19293651-b1bbd94eaca4a61b.png?imageMogr2/auto-orient/strip|imageView2/2/w/496/format/webp" alt="img" style="zoom:100%;"></p>
<p><img src="/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/image-20221015151341198.png" alt="image-20221015151341198" style="zoom:80%; margin:auto;"></p>
<p>θ控制差分卷积的贡献，即gradient-level的信息。</p>
<p>其实现代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/ZitongYu/CDCN/blob/master/CVPR2020_paper_codes/models/CDCNs.py</span></span><br><span class="line"><span class="comment"># vanilla convolution</span></span><br><span class="line">out_normal = self.conv(x)</span><br><span class="line"><span class="comment"># central difference term</span></span><br><span class="line">[C_out,C_in, kernel_size,kernel_size] = self.conv.weight.shape</span><br><span class="line">kernel_diff = self.conv.weight.<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>)</span><br><span class="line">kernel_diff = kernel_diff[:, :, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">out_diff = F.conv2d(<span class="built_in">input</span>=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride, padding=<span class="number">0</span>,                       groups=self.conv.groups)</span><br><span class="line"><span class="comment"># CDC OUTPUT</span></span><br><span class="line"><span class="keyword">return</span> out_normal - self.theta * out_diff</span><br></pre></td></tr></table></figure>
<h3 id="时空差分卷积（3D-CDC）"><a href="#时空差分卷积（3D-CDC）" class="headerlink" title="时空差分卷积（3D-CDC）"></a>时空差分卷积（3D-CDC）</h3><p>vanilla 3D的卷积操作难以感知细粒度的时空差异信息。Zitong Yu（这是什么怪物啊）设计了三种3D-CDC，用于不同场景下增强时域特征。</p>
<p><img src="https://pic4.zhimg.com/80/v2-6b6cbc16d5dd7fb0bc044b238e3a948f_720w.webp" alt="img" style="zoom:120%;"></p>
<ul>
<li>3D-CDC-ST：聚合局部时空区域内的所有中心差分信息，<strong>擅长动态纹理表征</strong>。</li>
<li>3D-CDC-T：聚合相邻帧间的局部时空区域内的中心差分信息，<strong>擅长捕捉精细的时域上下文信息</strong>。在PhysFormer里使用的就是这种差分卷积。</li>
<li>3D-CDC-TR：计算差分前采用temporal average pooling融合上下文信息，<strong>抗时域间噪声扰动</strong>。</li>
</ul>
<p>三种差分卷积的公式如下所示：</p>
<p><img src="/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/image-20221015172029434.png" alt="image-20221015172029434" style="zoom: 80%; margin:auto;"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/ZitongYu/3DCDC-NAS/blob/master/3DCDC.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vanilla</span></span><br><span class="line">self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,</span><br><span class="line">                      dilation=dilation, groups=groups, bias=bias)</span><br><span class="line">out_normal = self.conv(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># CDC_ST</span></span><br><span class="line">kernel_diff = self.conv.weight.<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>)</span><br><span class="line">kernel_diff = kernel_diff[:, :, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">out_diff = F.conv3d(<span class="built_in">input</span>=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride,</span><br><span class="line">                    padding=<span class="number">0</span>, dilation=self.conv.dilation, groups=self.conv.groups)</span><br><span class="line"><span class="keyword">return</span> out_normal - self.theta * out_diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># CDC_T</span></span><br><span class="line">kernel_diff = self.conv.weight[:, :, <span class="number">0</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>) + self.conv.weight[:, :, <span class="number">2</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>)</span><br><span class="line">kernel_diff = kernel_diff[:, :, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">out_diff = F.conv3d(<span class="built_in">input</span>=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride,</span><br><span class="line">                    padding=<span class="number">0</span>, dilation=self.conv.dilation, groups=self.conv.groups)</span><br><span class="line"><span class="keyword">return</span> out_normal - self.theta * out_diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># CDC_TR</span></span><br><span class="line">local_avg = self.avgpool(x)</span><br><span class="line">kernel_diff = self.conv.weight[:, :, <span class="number">0</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>) + self.conv.weight[:, :, <span class="number">2</span>, :, :].<span class="built_in">sum</span>(<span class="number">2</span>).<span class="built_in">sum</span>(<span class="number">2</span>)</span><br><span class="line">kernel_diff = kernel_diff[:, :, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">out_diff = F.conv3d(<span class="built_in">input</span>=local_avg, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride,</span><br><span class="line">                    padding=<span class="number">0</span>, groups=self.conv.groups)</span><br><span class="line"><span class="keyword">return</span> out_normal - self.theta * out_diff</span><br></pre></td></tr></table></figure>

        </div>
        
<blockquote class="copyright">
    <p><strong>本文链接 : </strong><a class="permalink" href="https://ymyforever.netlify.app/2022/09/27/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">https://ymyforever.netlify.app/2022/09/27/神经网络基础知识/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">文章目录</h3>
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#3D-CNN"><span class="toc-number">1.</span> <span class="toc-text">3D CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Conv3D"><span class="toc-number">1.1.</span> <span class="toc-text">Conv3D</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%88%86%E5%8D%B7%E7%A7%AF%EF%BC%88Difference-Convolution%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">差分卷积（Difference Convolution）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LBP%EF%BC%88Local-Binary-Patterns%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">LBP（Local Binary Patterns）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%E5%BF%83%E5%B7%AE%E5%88%86%E5%8D%B7%E7%A7%AF%EF%BC%88Central-Difference-Convolution%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">中心差分卷积（Central Difference Convolution）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E7%A9%BA%E5%B7%AE%E5%88%86%E5%8D%B7%E7%A7%AF%EF%BC%883D-CDC%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">时空差分卷积（3D-CDC）</span></a></li></ol></li></ol>
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/ymy-forever">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
